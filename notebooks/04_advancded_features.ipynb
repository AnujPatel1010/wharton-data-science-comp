{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e43654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features: 43\n",
      "Enhanced features: 65\n",
      "New features added: 22\n",
      "\n",
      "âœ… Saved: data/processed/model_input_enhanced.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load\n",
    "model_input = pd.read_csv(\"../data/processed/model_input.csv\")\n",
    "print(f\"Original features: {model_input.shape[1]}\")\n",
    "\n",
    "# INTERACTION FEATURES (differences matter more than absolute values)\n",
    "model_input['win_rate_diff'] = model_input['home_win_rate'] - model_input['away_win_rate']\n",
    "model_input['xg_diff'] = model_input['home_xg'] - model_input['away_xg']\n",
    "model_input['shots_diff'] = model_input['home_shots'] - model_input['away_shots']\n",
    "model_input['goal_diff_diff'] = model_input['home_goal_diff'] - model_input['away_goal_diff']\n",
    "model_input['first_eff_diff'] = model_input['home_first_eff'] - model_input['away_first_eff']\n",
    "model_input['second_eff_diff'] = model_input['home_second_eff'] - model_input['away_second_eff']\n",
    "model_input['disparity_diff'] = model_input['home_offensive_disparity'] - model_input['away_offensive_disparity']\n",
    "\n",
    "# RATIO FEATURES (relative strength)\n",
    "model_input['xg_ratio'] = model_input['home_xg'] / (model_input['away_xg'] + 0.001)\n",
    "model_input['shots_ratio'] = model_input['home_shots'] / (model_input['away_shots'] + 0.001)\n",
    "model_input['first_eff_ratio'] = model_input['home_first_eff'] / (model_input['away_first_eff'] + 0.001)\n",
    "\n",
    "# POLYNOMIAL FEATURES (capture non-linear relationships)\n",
    "model_input['home_xg_squared'] = model_input['home_xg'] ** 2\n",
    "model_input['away_xg_squared'] = model_input['away_xg'] ** 2\n",
    "model_input['win_rate_diff_squared'] = model_input['win_rate_diff'] ** 2\n",
    "\n",
    "# PRODUCT FEATURES (capture interactions)\n",
    "model_input['home_xg_eff'] = model_input['home_xg'] * model_input['home_first_eff']\n",
    "model_input['away_xg_eff'] = model_input['away_xg'] * model_input['away_first_eff']\n",
    "model_input['home_strength'] = model_input['home_win_rate'] * model_input['home_xg'] * model_input['home_first_eff']\n",
    "model_input['away_strength'] = model_input['away_win_rate'] * model_input['away_xg'] * model_input['away_first_eff']\n",
    "model_input['strength_diff'] = model_input['home_strength'] - model_input['away_strength']\n",
    "\n",
    "# AGGREGATED FEATURES (team quality indicators)\n",
    "model_input['home_total_line_xg'] = model_input['home_first_xg'] + model_input['home_second_xg']\n",
    "model_input['away_total_line_xg'] = model_input['away_first_xg'] + model_input['away_second_xg']\n",
    "model_input['home_avg_line_eff'] = (model_input['home_first_eff'] + model_input['home_second_eff']) / 2\n",
    "model_input['away_avg_line_eff'] = (model_input['away_first_eff'] + model_input['away_second_eff']) / 2\n",
    "\n",
    "print(f\"Enhanced features: {model_input.shape[1]}\")\n",
    "print(f\"New features added: {model_input.shape[1] - 43}\")\n",
    "\n",
    "# Save enhanced dataset\n",
    "model_input.to_csv(\"../data/processed/model_input_enhanced.csv\", index=False)\n",
    "print(\"\\nâœ… Saved: data/processed/model_input_enhanced.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb11aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 57\n",
      "Train: (1049, 57)\n",
      "Test: (263, 57)\n"
     ]
    }
   ],
   "source": [
    "# Exclude leaky columns\n",
    "exclude_cols = ['game_id', 'home_team', 'away_team', 'home_win', 'home_goals', 'away_goals', \n",
    "                'home_assists', 'away_assists']\n",
    "feature_cols = [c for c in model_input.columns if c not in exclude_cols]\n",
    "\n",
    "X = model_input[feature_cols].fillna(0)\n",
    "y = model_input['home_win']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f602215a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TUNING XGBOOST\n",
      "============================================================\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "âœ… Best XGBoost AUC: 0.6537\n",
      "Time: 1.2 minutes\n",
      "\n",
      "Best parameters:\n",
      "  subsample: 0.7\n",
      "  reg_lambda: 0.5\n",
      "  reg_alpha: 0\n",
      "  n_estimators: 100\n",
      "  min_child_weight: 1\n",
      "  max_depth: 4\n",
      "  learning_rate: 0.01\n",
      "  gamma: 0\n",
      "  colsample_bytree: 0.6\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TUNING XGBOOST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [0.5, 1, 1.5, 2]\n",
    "}\n",
    "\n",
    "xgb_base = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "start = time.time()\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    xgb_base,\n",
    "    param_distributions,\n",
    "    n_iter=50,  # Try 50 random combinations\n",
    "    cv=5,       # 5-fold cross-validation\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "best_xgb = xgb_search.best_estimator_\n",
    "pred_xgb = best_xgb.predict_proba(X_test)[:, 1]\n",
    "auc_xgb = roc_auc_score(y_test, pred_xgb)\n",
    "\n",
    "print(f\"\\nâœ… Best XGBoost AUC: {auc_xgb:.4f}\")\n",
    "print(f\"Time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"\\nBest parameters:\")\n",
    "for param, value in xgb_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(\"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1565d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TUNING LIGHTGBM\n",
      "============================================================\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "âœ… Best LightGBM AUC: 0.6489\n",
      "Time: 0.5 minutes\n",
      "\n",
      "Best parameters:\n",
      "  subsample: 0.9\n",
      "  reg_lambda: 0.1\n",
      "  reg_alpha: 0\n",
      "  num_leaves: 31\n",
      "  n_estimators: 300\n",
      "  min_child_samples: 50\n",
      "  max_depth: 3\n",
      "  learning_rate: 0.01\n",
      "  colsample_bytree: 0.6\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TUNING LIGHTGBM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'num_leaves': [15, 31, 63, 127],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
    "    'min_child_samples': [10, 20, 30, 50],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [0, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "lgb_base = LGBMClassifier(random_state=42, verbose=-1)\n",
    "\n",
    "start = time.time()\n",
    "lgb_search = RandomizedSearchCV(\n",
    "    lgb_base,\n",
    "    param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lgb_search.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "best_lgb = lgb_search.best_estimator_\n",
    "pred_lgb = best_lgb.predict_proba(X_test)[:, 1]\n",
    "auc_lgb = roc_auc_score(y_test, pred_lgb)\n",
    "\n",
    "print(f\"\\nâœ… Best LightGBM AUC: {auc_lgb:.4f}\")\n",
    "print(f\"Time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"\\nBest parameters:\")\n",
    "for param, value in lgb_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(\"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f12d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TUNING CATBOOST\n",
      "============================================================\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "âœ… Best CatBoost AUC: 0.6838\n",
      "Time: 4.0 minutes\n",
      "\n",
      "Best parameters:\n",
      "  random_strength: 1\n",
      "  learning_rate: 0.03\n",
      "  l2_leaf_reg: 1\n",
      "  iterations: 200\n",
      "  depth: 5\n",
      "  border_count: 32\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TUNING CATBOOST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "param_distributions = {\n",
    "    'iterations': [100, 200, 300, 500],\n",
    "    'depth': [4, 5, 6, 7, 8],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7],\n",
    "    'border_count': [32, 64, 128],\n",
    "    'random_strength': [0, 1, 2, 3]\n",
    "}\n",
    "\n",
    "cat_base = CatBoostClassifier(random_seed=42, verbose=False)\n",
    "\n",
    "start = time.time()\n",
    "cat_search = RandomizedSearchCV(\n",
    "    cat_base,\n",
    "    param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "cat_search.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "best_cat = cat_search.best_estimator_\n",
    "pred_cat = best_cat.predict_proba(X_test)[:, 1]\n",
    "auc_cat = roc_auc_score(y_test, pred_cat)\n",
    "\n",
    "print(f\"\\nâœ… Best CatBoost AUC: {auc_cat:.4f}\")\n",
    "print(f\"Time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"\\nBest parameters:\")\n",
    "for param, value in cat_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(\"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fdbaa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BUILDING STACKING ENSEMBLE\n",
      "============================================================\n",
      "Training stacking ensemble (this takes time)...\n",
      "\n",
      "âœ… STACKING ENSEMBLE AUC: 0.6706\n",
      "Time: 0.1 minutes\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BUILDING STACKING ENSEMBLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Base models (use best tuned models)\n",
    "base_models = [\n",
    "    ('xgb', best_xgb),\n",
    "    ('lgb', best_lgb),\n",
    "    ('cat', best_cat)\n",
    "]\n",
    "\n",
    "# Meta-learner (trains on base model predictions)\n",
    "meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Stacking classifier\n",
    "stacking = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_learner,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training stacking ensemble (this takes time)...\")\n",
    "start = time.time()\n",
    "stacking.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "pred_stacking = stacking.predict_proba(X_test)[:, 1]\n",
    "auc_stacking = roc_auc_score(y_test, pred_stacking)\n",
    "\n",
    "print(f\"\\nâœ… STACKING ENSEMBLE AUC: {auc_stacking:.4f}\")\n",
    "print(f\"Time: {elapsed/60:.1f} minutes\")\n",
    "print(\"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba7a3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL MODEL COMPARISON\n",
      "============================================================\n",
      "            Model      AUC      Features  Improvement  Rank\n",
      "Baseline Logistic 0.690000 28 (original)     0.000000     1\n",
      "   Tuned CatBoost 0.683784 57 (enhanced)    -0.006216     2\n",
      "Stacking Ensemble 0.670564 57 (enhanced)    -0.019436     3\n",
      "    Tuned XGBoost 0.653702 57 (enhanced)    -0.036298     4\n",
      "   Tuned LightGBM 0.648942 57 (enhanced)    -0.041058     5\n",
      "============================================================\n",
      "\n",
      "ðŸ† BEST MODEL: Baseline Logistic\n",
      "   AUC: 0.6900\n",
      "   Improvement over baseline: +0.0000 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Baseline Logistic', 'Tuned XGBoost', 'Tuned LightGBM', 'Tuned CatBoost', 'Stacking Ensemble'],\n",
    "    'AUC': [0.6900, auc_xgb, auc_lgb, auc_cat, auc_stacking],\n",
    "    'Features': ['28 (original)', f'{len(feature_cols)} (enhanced)', f'{len(feature_cols)} (enhanced)', \n",
    "                 f'{len(feature_cols)} (enhanced)', f'{len(feature_cols)} (enhanced)']\n",
    "}).sort_values('AUC', ascending=False)\n",
    "\n",
    "results['Improvement'] = results['AUC'] - 0.6900\n",
    "results['Rank'] = range(1, len(results) + 1)\n",
    "\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_model_name = results.iloc[0]['Model']\n",
    "best_auc = results.iloc[0]['AUC']\n",
    "improvement = results.iloc[0]['Improvement']\n",
    "\n",
    "print(f\"\\nðŸ† BEST MODEL: {best_model_name}\")\n",
    "print(f\"   AUC: {best_auc:.4f}\")\n",
    "print(f\"   Improvement over baseline: +{improvement:.4f} ({improvement/0.69*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edc525cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: CatBoost\n",
      "âœ… Saved: outputs/final_optimized_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Determine best model\n",
    "if auc_stacking >= max(auc_xgb, auc_lgb, auc_cat):\n",
    "    final_model = stacking\n",
    "    model_name = 'Stacking Ensemble'\n",
    "elif auc_xgb >= max(auc_lgb, auc_cat):\n",
    "    final_model = best_xgb\n",
    "    model_name = 'XGBoost'\n",
    "elif auc_lgb >= auc_cat:\n",
    "    final_model = best_lgb\n",
    "    model_name = 'LightGBM'\n",
    "else:\n",
    "    final_model = best_cat\n",
    "    model_name = 'CatBoost'\n",
    "\n",
    "print(f\"Selected model: {model_name}\")\n",
    "\n",
    "# Save\n",
    "with open('../outputs/final_optimized_model.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': final_model,\n",
    "        'scaler': scaler,\n",
    "        'feature_cols': feature_cols,\n",
    "        'auc': best_auc,\n",
    "        'model_name': model_name\n",
    "    }, f)\n",
    "\n",
    "print(f\"âœ… Saved: outputs/final_optimized_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc474826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating optimized predictions...\n",
      "\n",
      "game_1: brazil       vs kazakhstan   â†’ 79.1%\n",
      "game_2: netherlands  vs mongolia     â†’ 73.7%\n",
      "game_3: peru         vs rwanda       â†’ 75.8%\n",
      "game_4: thailand     vs oman         â†’ 80.0%\n",
      "game_5: pakistan     vs germany      â†’ 72.3%\n",
      "game_6: india        vs usa          â†’ 61.9%\n",
      "game_7: panama       vs switzerland  â†’ 80.0%\n",
      "game_8: iceland      vs canada       â†’ 64.4%\n",
      "game_9: china        vs france       â†’ 74.6%\n",
      "game_10: philippines  vs morocco      â†’ 62.7%\n",
      "game_11: ethiopia     vs saudi_arabia â†’ 68.3%\n",
      "game_12: singapore    vs new_zealand  â†’ 71.6%\n",
      "game_13: guatemala    vs south_korea  â†’ 70.6%\n",
      "game_14: uk           vs mexico       â†’ 69.5%\n",
      "game_15: vietnam      vs serbia       â†’ 57.9%\n",
      "game_16: indonesia    vs uae          â†’ 61.9%\n",
      "\n",
      "============================================================\n",
      "âœ… SAVED: outputs/round1_predictions_optimized.csv\n",
      "ðŸ“Š Model: CatBoost\n",
      "ðŸ“Š AUC: 0.6900\n",
      "ðŸ“Š Improvement: +0.0000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load matchups\n",
    "matchups = pd.read_excel(\"../data/raw/WHSDSC_Rnd1_matchups.xlsx\")\n",
    "\n",
    "# Load original model_input to build team features\n",
    "model_input_orig = pd.read_csv(\"../data/processed/model_input_enhanced.csv\")\n",
    "\n",
    "# Build team features (with ALL enhanced features)\n",
    "all_home_cols = [c for c in model_input_orig.columns if c.startswith('home_') \n",
    "                 and c not in ['home_team', 'home_win', 'home_goals', 'home_assists']]\n",
    "\n",
    "team_features_dict = {}\n",
    "for team in model_input_orig['home_team'].unique():\n",
    "    home_games = model_input_orig[model_input_orig['home_team'] == team]\n",
    "    home_stats = home_games[all_home_cols].mean()\n",
    "    \n",
    "    away_games = model_input_orig[model_input_orig['away_team'] == team]\n",
    "    away_cols = [c.replace('home_', 'away_') for c in all_home_cols]\n",
    "    away_stats = away_games[away_cols].mean()\n",
    "    \n",
    "    combined_stats = {}\n",
    "    for col in all_home_cols:\n",
    "        base = col.replace('home_', '')\n",
    "        combined_stats[base] = home_stats[col]\n",
    "    \n",
    "    team_features_dict[team] = combined_stats\n",
    "\n",
    "# Generate predictions\n",
    "predictions_optimized = []\n",
    "\n",
    "print(\"Generating optimized predictions...\\n\")\n",
    "\n",
    "for _, row in matchups.iterrows():\n",
    "    game_id = row['game_id']\n",
    "    home = row['home_team'].lower().strip()\n",
    "    away = row['away_team'].lower().strip()\n",
    "    \n",
    "    home_feats = team_features_dict.get(home, {})\n",
    "    away_feats = team_features_dict.get(away, {})\n",
    "    \n",
    "    # Build feature row with ALL enhanced features\n",
    "    feature_dict = {}\n",
    "    for col in feature_cols:\n",
    "        if col.startswith('home_'):\n",
    "            base = col.replace('home_', '')\n",
    "            feature_dict[col] = home_feats.get(base, 0)\n",
    "        elif col.startswith('away_'):\n",
    "            base = col.replace('away_', '')\n",
    "            feature_dict[col] = away_feats.get(base, 0)\n",
    "        else:\n",
    "            # Handle interaction features\n",
    "            if col in ['win_rate_diff', 'xg_diff', 'shots_diff', 'goal_diff_diff',\n",
    "                      'first_eff_diff', 'second_eff_diff', 'disparity_diff']:\n",
    "                home_base = col.replace('_diff', '')\n",
    "                feature_dict[col] = home_feats.get(home_base, 0) - away_feats.get(home_base, 0)\n",
    "            elif '_ratio' in col:\n",
    "                parts = col.replace('_ratio', '').split('_')\n",
    "                home_val = home_feats.get('_'.join(parts), 0)\n",
    "                away_val = away_feats.get('_'.join(parts), 0)\n",
    "                feature_dict[col] = home_val / (away_val + 0.001)\n",
    "            elif '_squared' in col:\n",
    "                base = col.replace('_squared', '')\n",
    "                if 'home' in base:\n",
    "                    val = home_feats.get(base.replace('home_', ''), 0)\n",
    "                elif 'away' in base:\n",
    "                    val = away_feats.get(base.replace('away_', ''), 0)\n",
    "                else:\n",
    "                    val = feature_dict.get(base, 0)\n",
    "                feature_dict[col] = val ** 2\n",
    "            else:\n",
    "                feature_dict[col] = 0\n",
    "    \n",
    "    X_game = pd.DataFrame([feature_dict])[feature_cols].fillna(0)\n",
    "    X_game_scaled = scaler.transform(X_game)\n",
    "    \n",
    "    prob = final_model.predict_proba(X_game_scaled)[0, 1]\n",
    "    \n",
    "    predictions_optimized.append({\n",
    "        'game_id': game_id,\n",
    "        'home_win_prob': prob\n",
    "    })\n",
    "    \n",
    "    print(f\"{game_id}: {home:12} vs {away:12} â†’ {prob:.1%}\")\n",
    "\n",
    "# Save\n",
    "submission_optimized = pd.DataFrame(predictions_optimized)\n",
    "submission_optimized.to_csv(\"../outputs/round1_predictions_optimized.csv\", index=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ… SAVED: outputs/round1_predictions_optimized.csv\")\n",
    "print(f\"ðŸ“Š Model: {model_name}\")\n",
    "print(f\"ðŸ“Š AUC: {best_auc:.4f}\")\n",
    "print(f\"ðŸ“Š Improvement: +{improvement:.4f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f3edaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS-VALIDATION SCORES:\n",
      "============================================================\n",
      "XGBoost CV AUC: 0.6832\n",
      "LightGBM CV AUC: 0.6799\n",
      "CatBoost CV AUC: 0.6875\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"CROSS-VALIDATION SCORES:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"XGBoost CV AUC: {xgb_search.best_score_:.4f}\")\n",
    "print(f\"LightGBM CV AUC: {lgb_search.best_score_:.4f}\")\n",
    "print(f\"CatBoost CV AUC: {cat_search.best_score_:.4f}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94609d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR ANALYSIS:\n",
      "============================================================\n",
      "Total test samples: 263\n",
      "Correct predictions: 173 (65.8%)\n",
      "Incorrect predictions: 90 (34.2%)\n",
      "\n",
      "High-confidence errors: 24\n",
      "\n",
      "Top 5 high-confidence errors:\n",
      "        home_team    away_team  predicted_prob  actual\n",
      "566        brazil       mexico        0.876216       0\n",
      "700      pakistan           uk        0.827159       0\n",
      "1292     mongolia       mexico        0.181920       1\n",
      "79        iceland  netherlands        0.182505       1\n",
      "1     switzerland   kazakhstan        0.184776       1\n",
      "\n",
      "Close predictions (40-60%): 87\n",
      "Accuracy on close games: 60.9%\n",
      "\n",
      "Mismatches (>20% win rate diff): 17\n",
      "Accuracy on mismatches: 70.6%\n",
      "\n",
      "Balanced games (<10% win rate diff): 162\n",
      "Accuracy on balanced: 63.0%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "# Load baseline\n",
    "model = pickle.load(open(\"../outputs/baseline_model.pkl\", \"rb\"))\n",
    "scaler = pickle.load(open(\"../outputs/baseline_scaler.pkl\", \"rb\"))\n",
    "model_input = pd.read_csv(\"../data/processed/model_input.csv\")\n",
    "\n",
    "# Get baseline features\n",
    "feature_cols = list(scaler.feature_names_in_)\n",
    "X = model_input[feature_cols].fillna(0)\n",
    "y = model_input['home_win']\n",
    "\n",
    "# Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predictions\n",
    "probs = model.predict_proba(X_test_scaled)[:, 1]\n",
    "preds = (probs > 0.5).astype(int)\n",
    "\n",
    "# Analyze errors\n",
    "test_df = model_input.loc[X_test.index].copy()\n",
    "test_df['predicted_prob'] = probs\n",
    "test_df['predicted'] = preds\n",
    "test_df['actual'] = y_test.values\n",
    "test_df['correct'] = (test_df['predicted'] == test_df['actual'])\n",
    "test_df['error_magnitude'] = np.abs(test_df['predicted_prob'] - test_df['actual'])\n",
    "\n",
    "# Find patterns in errors\n",
    "print(\"ERROR ANALYSIS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Correct predictions: {test_df['correct'].sum()} ({test_df['correct'].mean()*100:.1f}%)\")\n",
    "print(f\"Incorrect predictions: {(~test_df['correct']).sum()} ({(~test_df['correct']).mean()*100:.1f}%)\")\n",
    "\n",
    "# High-confidence errors (model was sure but wrong)\n",
    "high_conf_errors = test_df[(~test_df['correct']) & ((test_df['predicted_prob'] > 0.7) | (test_df['predicted_prob'] < 0.3))]\n",
    "print(f\"\\nHigh-confidence errors: {len(high_conf_errors)}\")\n",
    "\n",
    "if len(high_conf_errors) > 0:\n",
    "    print(\"\\nTop 5 high-confidence errors:\")\n",
    "    print(high_conf_errors.nlargest(5, 'error_magnitude')[['home_team', 'away_team', 'predicted_prob', 'actual']].to_string())\n",
    "\n",
    "# Close games (hardest to predict)\n",
    "close_games = test_df[test_df['predicted_prob'].between(0.4, 0.6)]\n",
    "print(f\"\\nClose predictions (40-60%): {len(close_games)}\")\n",
    "print(f\"Accuracy on close games: {close_games['correct'].mean()*100:.1f}%\")\n",
    "\n",
    "# Mismatches (strong vs weak teams)\n",
    "test_df['win_rate_diff'] = test_df['home_win_rate'] - test_df['away_win_rate']\n",
    "mismatches = test_df[test_df['win_rate_diff'].abs() > 0.2]\n",
    "print(f\"\\nMismatches (>20% win rate diff): {len(mismatches)}\")\n",
    "print(f\"Accuracy on mismatches: {mismatches['correct'].mean()*100:.1f}%\")\n",
    "\n",
    "balanced = test_df[test_df['win_rate_diff'].abs() < 0.1]\n",
    "print(f\"\\nBalanced games (<10% win rate diff): {len(balanced)}\")\n",
    "print(f\"Accuracy on balanced: {balanced['correct'].mean()*100:.1f}%\")\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
